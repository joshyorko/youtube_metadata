name: transcribe-service

services:
  transcribe-service:
    build: ./transcribe_service
    container_name: transcribe-service
    ports:
      - "8000:8000"
    volumes:
      - ./transcribe_service:/app
    environment:
      - SERVICE_ENV="development"
    networks:
      - app_network
    restart: always
    command: ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--reload", "--port", "8000"]
    # CPU is default configuration
    # GPU configuration is applied when using the 'gpu' profile

  transcribe-service-gpu:
    profiles:
      - gpu
    extends:
      service: transcribe-service
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    runtime: nvidia
    environment:
      - SERVICE_ENV="development"
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility

networks:
  app_network:
    driver: bridge

volumes:
  app_data:
    driver: local