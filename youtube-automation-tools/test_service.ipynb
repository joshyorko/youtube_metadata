{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Optional\n",
    "from indy_dev_tools.models import IdtConfig\n",
    "from indy_dev_tools.modules.idt_config import load_config\n",
    "import sys\n",
    "from openai import OpenAI\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "ULTIMATE_YT_CREATOR_INSTRUCTION = \"You work with Mr. Beast to create the best Youtube Content on the planet. You care deeply about your craft, your community and the output of your work above all else. Every dollar, and every minute of your time goes back into making the best youtube content in the world.\"\n",
    "def make_cap_refs(prompt: str, refs: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    Attach capitalized references to the prompt.\n",
    "    \"\"\"\n",
    "\n",
    "    for key, value in refs.items():\n",
    "        prompt += f\"\\n\\n{key.upper()}\\n\\n{value}\"\n",
    "\n",
    "    return prompt\n",
    "def prompt_json_response(\n",
    "    prompt: str,\n",
    "    openai_key: str,\n",
    "    model: str = \"gpt-4-0125-preview\",\n",
    "    instructions: str = \"You are a helpful assistant.\",\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate a response from a prompt using the OpenAI API.\n",
    "\n",
    "    Example:\n",
    "        res = llm.prompt_json_response(\n",
    "            f\"You're a data innovator. You analyze SQL databases table structure and generate 3 novel insights for your team to reflect on and query.\n",
    "            Generate insights for this this prompt: {prompt}.\n",
    "            Format your insights in JSON format. Respond in this json format [{{insight, sql, actionable_business_value}}, ...]\",\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    if not openai_key:\n",
    "        sys.exit(\n",
    "            \"\"\"\n",
    "ERORR: OpenAI API key not found. Please export your key to OPENAI_API_KEY\n",
    "Example bash command:\n",
    "    export OPENAI_API_KEY=<your openai apikey>\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "    openai.api_key = openai_key\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": instructions,  # Added instructions as a system message\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "ART_STYLES = [\n",
    "    \"Steampunk\",\n",
    "    \"Art Deco\",\n",
    "    \"Abstract Expressionism\",\n",
    "    \"Pointillism\",\n",
    "    \"Cubism\",\n",
    "    \"Gothic\",\n",
    "    \"Pop art\",\n",
    "    \"Psychedelic\",\n",
    "    \"Impressionism\",\n",
    "    \"Fauvism\",\n",
    "    \"Glitch Art\",\n",
    "    \"Trompe L’oeil\",\n",
    "    \"Chiaroscuro\",\n",
    "    \"Minimalist\",\n",
    "    \"Flat Design\",\n",
    "    \"Surface Detail\",\n",
    "    \"Halftone\",\n",
    "    \"Grid\",\n",
    "    \"Guilloché Patterns\",\n",
    "    \"Celtic Maze\",\n",
    "    \"Glassmorphism\",\n",
    "    \"Morphism\",\n",
    "    \"Bauhaus\",\n",
    "    \"Art Nouveau\",\n",
    "    \"Baroque\",\n",
    "    \"Postmodernism\",\n",
    "    \"Industrial\",\n",
    "    \"Mid-Century Modern\",\n",
    "    \"Scandinavian\",\n",
    "    \"Japanese\",\n",
    "    \"Mediterranean\",\n",
    "    \"Bohemian\",\n",
    "    \"Cyberpunk\",\n",
    "    \"Sci-fi\",\n",
    "    \"Eclectic\",\n",
    "    \"Transitional\",\n",
    "    \"Urban\",\n",
    "    \"Global\",\n",
    "    \"Naturalistic\",\n",
    "    \"Geometric\",\n",
    "    \"Dada\",\n",
    "    \"Dada midjourney style prompt\",\n",
    "    \"Opulent\",\n",
    "    \"Synthetism\",\n",
    "    \"Tachisme\",\n",
    "    \"Symbolism\",\n",
    "    \"Neo-Expressionism\",\n",
    "    \"Vaporware\",\n",
    "    \"Vaporware Midjourney Style Prompt\",\n",
    "    \"Papercut\",\n",
    "    \"Papercut Midjourney Style Prompt\",\n",
    "    \"Pixel Art\",\n",
    "    \"Pixel art Midjourney Style Prompt\",\n",
    "    \"Bokeh\",\n",
    "]\n",
    "\n",
    "THUMBNAIL_PROMPT = \"\"\"{ULTIMATE_YT_CREATOR_INSTRUCTION} Create a compelling prompt that will be used to generate a thumbnail. Follow the RULE_SET_FOR_SUCCESS below to create the best prompt that will be used to generate a youtube thumbnail.\n",
    "\n",
    "RULE_SET_FOR_SUCCESS:\n",
    "- You create a prompt that is 2-3 sentences long.\n",
    "- Create {count} descriptions for your next video. \n",
    "- Respond strictly in this json format: {high_quality_thumbnail_prompts: [{thumbnail_prompt, explanation}, ...]}\n",
    "- The thumbnail_prompt must have a unique take on the describe the draft title visually.\n",
    "- The prompt you create will be used to generate a thumbnail using generative AI.\n",
    "- Describe the thumbnail that best represents the draft title in a creative way.\n",
    "- Always specify 1 primary color and 1 secondary color that will be used in the thumbnail that will create a compelling image.\n",
    "- In addition to primary colors, define how colors are used: gradient, solid, flat, spiral, energetic, simple, minimal, etc.\n",
    "- We need a concise 2-3 sentence long describe of a unique, creative, engaging visual representation of the draft title.\n",
    "- With every thumbnail_prompt create a explanation, explaining the choices made in the thumbnail_prompt.\n",
    "- Use the additional information below to craft the thumbnail_prompt.\n",
    "- Be sure to use a {art_style} art style in the thumbnail_prompt.\n",
    "\n",
    "EXAMPLE:\n",
    "- draft_title: \"Using AI Copilots to write code for me\"\n",
    "- thumbnail_prompt: \"An engineer sits at a desk with a computer, while a robot sits next to him, typing on a keyboard. The human is relaxing, the robot is working. The primary color is blue, the secondary color is white. Colors are used in a minimalist style.\"\n",
    "- explanation: \"The human is relaxing while the robot is working, this is a unique take on the draft title. The primary color is blue, the secondary color is white. Colors are used in a minimalist style.\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def create_thumbnail_prompt(\n",
    "    count: int,\n",
    "    draft_title: str,\n",
    "    seo_keywords: Optional[str] = None,\n",
    "    art_style: Optional[str] = None,\n",
    "):\n",
    "    config: IdtConfig = load_config()\n",
    "\n",
    "    cap_refs = {\"draft_title\": draft_title}\n",
    "\n",
    "  \n",
    "    selected_art_style = art_style if art_style else random.choice(ART_STYLES)\n",
    "\n",
    "    prompt = THUMBNAIL_PROMPT.replace(\"{count}\", str(count))\n",
    "    prompt = prompt.replace(\"{art_style}\", selected_art_style)\n",
    "    prompt = prompt.replace(\n",
    "        \"{ULTIMATE_YT_CREATOR_INSTRUCTION}\", ULTIMATE_YT_CREATOR_INSTRUCTION\n",
    "    )\n",
    "\n",
    "    prompt = make_cap_refs(prompt, cap_refs)\n",
    "\n",
    "    # print(f\"Running prompt: {prompt}\")\n",
    "\n",
    "    response = prompt_json_response(\n",
    "        prompt,\n",
    "        openai_key=config.yt.openai_api_key,\n",
    "        instructions=\"Create a compelling description of a thumbnail that will captive viewers.\",\n",
    "    )\n",
    "\n",
    "    # Write the thumbnail prompt to a file\n",
    "    if config.yt.thumbnail_prompt_file_path:\n",
    "        with open(config.yt.thumbnail_prompt_file_path, \"w\") as file:\n",
    "            file.write(response)\n",
    "            print(f\"Thumbnail prompt written to {config.yt.thumbnail_prompt_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from rich import print as rprint\n",
    "import uuid\n",
    "\n",
    "def download_image(image_url, save_path):\n",
    "    response = requests.get(image_url)\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        rprint(f\"Image downloaded successfully: {save_path}\")\n",
    "    else:\n",
    "        rprint(\"Failed to download image.\")\n",
    "\n",
    "def generate_thumbnail(description):\n",
    "    url = \"http://localhost:8001/generate-thumbnail/\"  # Adjust this URL based on your setup\n",
    "    payload = {'description': description}\n",
    "    response = requests.post(url, json=payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        rprint(\"Thumbnail generation successful!\")\n",
    "        data = response.json()\n",
    "        image_url = data['data'][0]['url']\n",
    "        rprint(\"Thumbnail URL:\", image_url)\n",
    "        rprint(\"Revised Prompt:\", data['data'][0]['revised_prompt'])\n",
    "        \n",
    "        # Specify the path where you want to save the image\n",
    "        save_path = str(uuid.uuid4()) + \"-downloaded_thumbnail.jpg\"\n",
    "        download_image(image_url, save_path)\n",
    "    else:\n",
    "        rprint(\"Failed to generate thumbnail. Status code:\", response.status_code)\n",
    "        rprint(\"Response:\", response.text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    description = \"Futuristic scene reminiscent of movie Ready Player One, super photorealistic, 4k\"  # Example description\n",
    "    generate_thumbnail(description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['data'][0]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from rich import print as rprint\n",
    "\n",
    "def transcribe_audio(file_path):\n",
    "    url = \"http://localhost:8000/transcribe/\"  # Adjust this URL based on your setup\n",
    "    files = {'file': open(file_path, 'rb')}\n",
    "    response = requests.post(url, files=files)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        print(\"Transcription successful!\")\n",
    "        data = response.json()\n",
    "        # You can also print additional information, like detected language, if your response includes that\n",
    "    else:\n",
    "        print(\"Failed to transcribe audio. Status code:\", response.status_code)\n",
    "        print(\"Response:\", response.text)\n",
    "    return data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"audio.mp3\"  # Adjust this to the path of your audio file\n",
    "    response = transcribe_audio(file_path)\n",
    "    rprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "response = client.images.generate(\n",
    "  model=\"dall-e-3\",\n",
    "  prompt=\"a white siamese cat\",\n",
    "  size=\"1024x1024\",\n",
    "  quality=\"standard\",\n",
    "  n=1,\n",
    ")\n",
    "\n",
    "image_url = response.data[0].url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(f\"Response Data: {response.model_dump_json()}\")\n",
    "rprint(f\"Generated Image URL: {image_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"tiny\")\n",
    "\n",
    "# load audio and pad/trim it to fit 30 seconds\n",
    "audio = whisper.load_audio(\"audio.mp3\")\n",
    "audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "# make log-Mel spectrogram and move to the same device as the model\n",
    "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "# detect the spoken language\n",
    "_, probs = model.detect_language(mel)\n",
    "print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "\n",
    "# decode the audio\n",
    "options = whisper.DecodingOptions()\n",
    "result = whisper.decode(model, mel, options)\n",
    "\n",
    "# print the recognized text\n",
    "print(result.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
