[Skip to content](https://github.com/SYSTRAN/<#start-of-content>)
## Navigation Menu
Toggle navigation
[ ](https://github.com/SYSTRAN/</>)
[ Sign in ](https://github.com/SYSTRAN/</login?return_to=https%3A%2F%2Fgithub.com%2FSYSTRAN%2Ffaster-whisper>)
  * Product 
    * [ GitHub Copilot Write better code with AI  ](https://github.com/SYSTRAN/<https:/github.com/features/copilot>)
    * [ Security Find and fix vulnerabilities  ](https://github.com/SYSTRAN/<https:/github.com/features/security>)
    * [ Actions Automate any workflow  ](https://github.com/SYSTRAN/<https:/github.com/features/actions>)
    * [ Codespaces Instant dev environments  ](https://github.com/SYSTRAN/<https:/github.com/features/codespaces>)
    * [ Issues Plan and track work  ](https://github.com/SYSTRAN/<https:/github.com/features/issues>)
    * [ Code Review Manage code changes  ](https://github.com/SYSTRAN/<https:/github.com/features/code-review>)
    * [ Discussions Collaborate outside of code  ](https://github.com/SYSTRAN/<https:/github.com/features/discussions>)
    * [ Code Search Find more, search less  ](https://github.com/SYSTRAN/<https:/github.com/features/code-search>)
Explore
    * [ All features ](https://github.com/SYSTRAN/<https:/github.com/features>)
    * [ Documentation ](https://github.com/SYSTRAN/<https:/docs.github.com>)
    * [ GitHub Skills ](https://github.com/SYSTRAN/<https:/skills.github.com>)
    * [ Blog ](https://github.com/SYSTRAN/<https:/github.blog>)
  * Solutions 
By company size
    * [ Enterprises ](https://github.com/SYSTRAN/<https:/github.com/enterprise>)
    * [ Small and medium teams ](https://github.com/SYSTRAN/<https:/github.com/team>)
    * [ Startups ](https://github.com/SYSTRAN/<https:/github.com/enterprise/startups>)
    * [ Nonprofits ](https://github.com/SYSTRAN/</solutions/industry/nonprofits>)
By use case
    * [ DevSecOps ](https://github.com/SYSTRAN/</solutions/use-case/devsecops>)
    * [ DevOps ](https://github.com/SYSTRAN/</solutions/use-case/devops>)
    * [ CI/CD ](https://github.com/SYSTRAN/</solutions/use-case/ci-cd>)
    * [ View all use cases ](https://github.com/SYSTRAN/</solutions/use-case>)
By industry
    * [ Healthcare ](https://github.com/SYSTRAN/</solutions/industry/healthcare>)
    * [ Financial services ](https://github.com/SYSTRAN/</solutions/industry/financial-services>)
    * [ Manufacturing ](https://github.com/SYSTRAN/</solutions/industry/manufacturing>)
    * [ Government ](https://github.com/SYSTRAN/</solutions/industry/government>)
    * [ View all industries ](https://github.com/SYSTRAN/</solutions/industry>)
[ View all solutions ](https://github.com/SYSTRAN/</solutions>)
  * Resources 
Topics
    * [ AI ](https://github.com/SYSTRAN/</resources/articles/ai>)
    * [ DevOps ](https://github.com/SYSTRAN/</resources/articles/devops>)
    * [ Security ](https://github.com/SYSTRAN/</resources/articles/security>)
    * [ Software Development ](https://github.com/SYSTRAN/</resources/articles/software-development>)
    * [ View all ](https://github.com/SYSTRAN/</resources/articles>)
Explore
    * [ Learning Pathways ](https://github.com/SYSTRAN/<https:/resources.github.com/learn/pathways>)
    * [ White papers, Ebooks, Webinars ](https://github.com/SYSTRAN/<https:/resources.github.com>)
    * [ Customer Stories ](https://github.com/SYSTRAN/<https:/github.com/customer-stories>)
    * [ Partners ](https://github.com/SYSTRAN/<https:/partner.github.com>)
    * [ Executive Insights ](https://github.com/SYSTRAN/<https:/github.com/solutions/executive-insights>)
  * Open Source 
    * [ GitHub Sponsors Fund open source developers  ](https://github.com/SYSTRAN/</sponsors>)
    * [ The ReadME Project GitHub community articles  ](https://github.com/SYSTRAN/<https:/github.com/readme>)
Repositories
    * [ Topics ](https://github.com/SYSTRAN/<https:/github.com/topics>)
    * [ Trending ](https://github.com/SYSTRAN/<https:/github.com/trending>)
    * [ Collections ](https://github.com/SYSTRAN/<https:/github.com/collections>)
  * Enterprise 
    * [ Enterprise platform AI-powered developer platform  ](https://github.com/SYSTRAN/</enterprise>)
Available add-ons
    * [ Advanced Security Enterprise-grade security features  ](https://github.com/SYSTRAN/<https:/github.com/enterprise/advanced-security>)
    * [ GitHub Copilot Enterprise-grade AI features  ](https://github.com/SYSTRAN/</features/copilot#enterprise>)
    * [ Premium Support Enterprise-grade 24/7 support  ](https://github.com/SYSTRAN/</premium-support>)
  * [Pricing](https://github.com/SYSTRAN/<https:/github.com/pricing>)


Search or jump to...
# Search code, repositories, users, issues, pull requests...
Search 
Clear
[Search syntax tips](https://github.com/SYSTRAN/<https:/docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax>)
#  Provide feedback 
We read every piece of feedback, and take your input very seriously.
Include my email address so I can be contacted
Cancel  Submit feedback 
#  Saved searches 
## Use saved searches to filter your results more quickly
Name
Query
To see all available qualifiers, see our [documentation](https://github.com/SYSTRAN/<https:/docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax>). 
Cancel  Create saved search 
[ Sign in ](https://github.com/SYSTRAN/</login?return_to=https%3A%2F%2Fgithub.com%2FSYSTRAN%2Ffaster-whisper>)
[ Sign up ](https://github.com/SYSTRAN/</signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=SYSTRAN%2Ffaster-whisper>) Reseting focus
You signed in with another tab or window. [Reload](https://github.com/SYSTRAN/<>) to refresh your session. You signed out in another tab or window. [Reload](https://github.com/SYSTRAN/<>) to refresh your session. You switched accounts on another tab or window. [Reload](https://github.com/SYSTRAN/<>) to refresh your session. Dismiss alert
{{ message }}
[ SYSTRAN ](https://github.com/SYSTRAN/</SYSTRAN>) / **[faster-whisper](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper>) ** Public
  * [ Notifications ](https://github.com/SYSTRAN/</login?return_to=%2FSYSTRAN%2Ffaster-whisper>) You must be signed in to change notification settings
  * [ Fork 1.2k ](https://github.com/SYSTRAN/</login?return_to=%2FSYSTRAN%2Ffaster-whisper>)
  * [ Star  14.1k ](https://github.com/SYSTRAN/</login?return_to=%2FSYSTRAN%2Ffaster-whisper>)


Faster Whisper transcription with CTranslate2 
### License
[ MIT license ](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/blob/master/LICENSE>)
[ 14.1k stars ](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/stargazers>) [ 1.2k forks ](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/forks>) [ Branches ](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/branches>) [ Tags ](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/tags>) [ Activity ](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/activity>)
[ Star  ](https://github.com/SYSTRAN/</login?return_to=%2FSYSTRAN%2Ffaster-whisper>)
[ Notifications ](https://github.com/SYSTRAN/</login?return_to=%2FSYSTRAN%2Ffaster-whisper>) You must be signed in to change notification settings
  * [ Code ](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper>)
  * [ Issues 225 ](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/issues>)
  * [ Pull requests 9 ](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/pulls>)
  * [ Discussions ](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/discussions>)
  * [ Actions ](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/actions>)
  * [ Security ](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/security>)
  * [ Insights ](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/pulse>)


Additional navigation options
  * [ Code  ](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper>)
  * [ Issues  ](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/issues>)
  * [ Pull requests  ](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/pulls>)
  * [ Discussions  ](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/discussions>)
  * [ Actions  ](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/actions>)
  * [ Security  ](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/security>)
  * [ Insights  ](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/pulse>)


# SYSTRAN/faster-whisper
master
[Branches](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/branches>)[Tags](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/tags>)
[](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/branches>)[](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/tags>)
Go to file
Code
## Folders and files
Name| Name| Last commit message| Last commit date  
---|---|---|---  
## Latest commit
## History
[245 Commits](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/commits/master/>)[](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/commits/master/>)  
[.github/workflows](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/tree/master/.github/workflows> "This path skips through empty directories")| [.github/workflows](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/tree/master/.github/workflows> "This path skips through empty directories")  
[benchmark](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/tree/master/benchmark> "benchmark")| [benchmark](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/tree/master/benchmark> "benchmark")  
[docker](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/tree/master/docker> "docker")| [docker](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/tree/master/docker> "docker")  
[faster_whisper](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/tree/master/faster_whisper> "faster_whisper")| [faster_whisper](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/tree/master/faster_whisper> "faster_whisper")  
[tests](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/tree/master/tests> "tests")| [tests](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/tree/master/tests> "tests")  
[.gitignore](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/blob/master/.gitignore> ".gitignore")| [.gitignore](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/blob/master/.gitignore> ".gitignore")  
[CONTRIBUTING.md](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/blob/master/CONTRIBUTING.md> "CONTRIBUTING.md")| [CONTRIBUTING.md](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/blob/master/CONTRIBUTING.md> "CONTRIBUTING.md")  
[LICENSE](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/blob/master/LICENSE> "LICENSE")| [LICENSE](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/blob/master/LICENSE> "LICENSE")  
[MANIFEST.in](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/blob/master/MANIFEST.in> "MANIFEST.in")| [MANIFEST.in](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/blob/master/MANIFEST.in> "MANIFEST.in")  
[README.md](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/blob/master/README.md> "README.md")| [README.md](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/blob/master/README.md> "README.md")  
[requirements.conversion.txt](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/blob/master/requirements.conversion.txt> "requirements.conversion.txt")| [requirements.conversion.txt](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/blob/master/requirements.conversion.txt> "requirements.conversion.txt")  
[requirements.txt](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/blob/master/requirements.txt> "requirements.txt")| [requirements.txt](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/blob/master/requirements.txt> "requirements.txt")  
[setup.cfg](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/blob/master/setup.cfg> "setup.cfg")| [setup.cfg](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/blob/master/setup.cfg> "setup.cfg")  
[setup.py](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/blob/master/setup.py> "setup.py")| [setup.py](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/blob/master/setup.py> "setup.py")  
View all files  
## Repository files navigation
  * [README](https://github.com/SYSTRAN/<#>)
  * [MIT license](https://github.com/SYSTRAN/<#>)


[![CI](https://github.com/SYSTRAN/faster-whisper/workflows/CI/badge.svg)](https://github.com/SYSTRAN/<https:/github.com/SYSTRAN/faster-whisper/actions?query=workflow%3ACI>) [![PyPI version](https://camo.githubusercontent.com/adfb8529785125e8bb83b5ca021e4b3e12588c267638fddded8f976c0978f03a/68747470733a2f2f62616467652e667572792e696f2f70792f6661737465722d776869737065722e737667)](https://github.com/SYSTRAN/<https:/badge.fury.io/py/faster-whisper>)
# Faster Whisper transcription with CTranslate2
[](https://github.com/SYSTRAN/<#faster-whisper-transcription-with-ctranslate2>)
**faster-whisper** is a reimplementation of OpenAI's Whisper model using [CTranslate2](https://github.com/SYSTRAN/<https:/github.com/OpenNMT/CTranslate2/>), which is a fast inference engine for Transformer models.
This implementation is up to 4 times faster than [openai/whisper](https://github.com/SYSTRAN/<https:/github.com/openai/whisper>) for the same accuracy while using less memory. The efficiency can be further improved with 8-bit quantization on both CPU and GPU.
## Benchmark
[](https://github.com/SYSTRAN/<#benchmark>)
### Whisper
[](https://github.com/SYSTRAN/<#whisper>)
For reference, here's the time and memory usage that are required to transcribe [**13 minutes**](https://github.com/SYSTRAN/<https:/www.youtube.com/watch?v=0u7tTptBo9I>) of audio using different implementations:
  * [openai/whisper](https://github.com/SYSTRAN/<https:/github.com/openai/whisper>)@[v20240930](https://github.com/SYSTRAN/<https:/github.com/openai/whisper/tree/v20240930>)
  * [whisper.cpp](https://github.com/SYSTRAN/<https:/github.com/ggerganov/whisper.cpp>)@[v1.7.2](https://github.com/SYSTRAN/<https:/github.com/ggerganov/whisper.cpp/tree/v1.7.2>)
  * [transformers](https://github.com/SYSTRAN/<https:/github.com/huggingface/transformers>)@[v4.46.3](https://github.com/SYSTRAN/<https:/github.com/huggingface/transformers/tree/v4.46.3>)
  * [faster-whisper](https://github.com/SYSTRAN/<https:/github.com/SYSTRAN/faster-whisper>)@[v1.1.0](https://github.com/SYSTRAN/<https:/github.com/SYSTRAN/faster-whisper/tree/v1.1.0>)


### Large-v2 model on GPU
[](https://github.com/SYSTRAN/<#large-v2-model-on-gpu>)
Implementation | Precision | Beam size | Time | VRAM Usage  
---|---|---|---|---  
openai/whisper | fp16 | 5 | 2m23s | 4708MB  
whisper.cpp (Flash Attention) | fp16 | 5 | 1m05s | 4127MB  
transformers (SDPA)[1](https://github.com/SYSTRAN/<#user-content-fn-1-1b7a39b9e8c4b08111340108775e2bdb>) | fp16 | 5 | 1m52s | 4960MB  
faster-whisper | fp16 | 5 | 1m03s | 4525MB  
faster-whisper (`batch_size=8`) | fp16 | 5 | 17s | 6090MB  
faster-whisper | int8 | 5 | 59s | 2926MB  
faster-whisper (`batch_size=8`) | int8 | 5 | 16s | 4500MB  
### distil-whisper-large-v3 model on GPU
[](https://github.com/SYSTRAN/<#distil-whisper-large-v3-model-on-gpu>)
Implementation | Precision | Beam size | Time | YT Commons WER  
---|---|---|---|---  
transformers (SDPA) (`batch_size=16`) | fp16 | 5 | 46m12s | 14.801  
faster-whisper (`batch_size=16`) | fp16 | 5 | 25m50s | 13.527  
_GPU Benchmarks are Executed with CUDA 12.4 on a NVIDIA RTX 3070 Ti 8GB._
### Small model on CPU
[](https://github.com/SYSTRAN/<#small-model-on-cpu>)
Implementation | Precision | Beam size | Time | RAM Usage  
---|---|---|---|---  
openai/whisper | fp32 | 5 | 6m58s | 2335MB  
whisper.cpp | fp32 | 5 | 2m05s | 1049MB  
whisper.cpp (OpenVINO) | fp32 | 5 | 1m45s | 1642MB  
faster-whisper | fp32 | 5 | 2m37s | 2257MB  
faster-whisper (`batch_size=8`) | fp32 | 5 | 1m06s | 4230MB  
faster-whisper | int8 | 5 | 1m42s | 1477MB  
faster-whisper (`batch_size=8`) | int8 | 5 | 51s | 3608MB  
_Executed with 8 threads on an Intel Core i7-12700K._
## Requirements
[](https://github.com/SYSTRAN/<#requirements>)
  * Python 3.9 or greater


Unlike openai-whisper, FFmpeg does **not** need to be installed on the system. The audio is decoded with the Python library [PyAV](https://github.com/SYSTRAN/<https:/github.com/PyAV-Org/PyAV>) which bundles the FFmpeg libraries in its package.
### GPU
[](https://github.com/SYSTRAN/<#gpu>)
GPU execution requires the following NVIDIA libraries to be installed:
  * [cuBLAS for CUDA 12](https://github.com/SYSTRAN/<https:/developer.nvidia.com/cublas>)
  * [cuDNN 9 for CUDA 12](https://github.com/SYSTRAN/<https:/developer.nvidia.com/cudnn>)


**Note** : The latest versions of `ctranslate2` only support CUDA 12 and cuDNN 9. For CUDA 11 and cuDNN 8, the current workaround is downgrading to the `3.24.0` version of `ctranslate2`, for CUDA 12 and cuDNN 8, downgrade to the `4.4.0` version of `ctranslate2`, (This can be done with `pip install --force-reinstall ctranslate2==4.4.0` or specifying the version in a `requirements.txt`).
There are multiple ways to install the NVIDIA libraries mentioned above. The recommended way is described in the official NVIDIA documentation, but we also suggest other installation methods below.
Other installation methods (click to expand)
**Note:** For all these methods below, keep in mind the above note regarding CUDA versions. Depending on your setup, you may need to install the _CUDA 11_ versions of libraries that correspond to the CUDA 12 libraries listed in the instructions below.
#### Use Docker
[](https://github.com/SYSTRAN/<#use-docker>)
The libraries (cuBLAS, cuDNN) are installed in this official NVIDIA CUDA Docker images: `nvidia/cuda:12.3.2-cudnn9-runtime-ubuntu22.04`.
#### Install with `pip` (Linux only)
[](https://github.com/SYSTRAN/<#install-with-pip-linux-only>)
On Linux these libraries can be installed with `pip`. Note that `LD_LIBRARY_PATH` must be set before launching Python.
```
pip install nvidia-cublas-cu12 nvidia-cudnn-cu12==9.*
export LD_LIBRARY_PATH=`python3 -c 'import os; import nvidia.cublas.lib; import nvidia.cudnn.lib; print(os.path.dirname(nvidia.cublas.lib.__file__) + ":" + os.path.dirname(nvidia.cudnn.lib.__file__))'`
```

#### Download the libraries from Purfview's repository (Windows & Linux)
[](https://github.com/SYSTRAN/<#download-the-libraries-from-purfviews-repository-windows--linux>)
Purfview's [whisper-standalone-win](https://github.com/SYSTRAN/<https:/github.com/Purfview/whisper-standalone-win>) provides the required NVIDIA libraries for Windows & Linux in a [single archive](https://github.com/SYSTRAN/<https:/github.com/Purfview/whisper-standalone-win/releases/tag/libs>). Decompress the archive and place the libraries in a directory included in the `PATH`.
## Installation
[](https://github.com/SYSTRAN/<#installation>)
The module can be installed from [PyPI](https://github.com/SYSTRAN/<https:/pypi.org/project/faster-whisper/>):
```
pip install faster-whisper
```

Other installation methods (click to expand)
### Install the master branch
[](https://github.com/SYSTRAN/<#install-the-master-branch>)
```
pip install --force-reinstall "faster-whisper @ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz"
```

### Install a specific commit
[](https://github.com/SYSTRAN/<#install-a-specific-commit>)
```
pip install --force-reinstall "faster-whisper @ https://github.com/SYSTRAN/faster-whisper/archive/a4f1cc8f11433e454c3934442b5e1a4ed5e865c3.tar.gz"
```

## Usage
[](https://github.com/SYSTRAN/<#usage>)
### Faster-whisper
[](https://github.com/SYSTRAN/<#faster-whisper>)
```
from faster_whisper import WhisperModel
model_size = "large-v3"
# Run on GPU with FP16
model = WhisperModel(model_size, device="cuda", compute_type="float16")
# or run on GPU with INT8
# model = WhisperModel(model_size, device="cuda", compute_type="int8_float16")
# or run on CPU with INT8
# model = WhisperModel(model_size, device="cpu", compute_type="int8")
segments, info = model.transcribe("audio.mp3", beam_size=5)
print("Detected language '%s' with probability %f" % (info.language, info.language_probability))
for segment in segments:
  print("[%.2fs -> %.2fs] %s" % (segment.start, segment.end, segment.text))
```

**Warning:** `segments` is a _generator_ so the transcription only starts when you iterate over it. The transcription can be run to completion by gathering the segments in a list or a `for` loop:
```
segments, _ = model.transcribe("audio.mp3")
segments = list(segments) # The transcription will actually run here.
```

### Batched Transcription
[](https://github.com/SYSTRAN/<#batched-transcription>)
The following code snippet illustrates how to run batched transcription on an example audio file. `BatchedInferencePipeline.transcribe` is a drop-in replacement for `WhisperModel.transcribe`
```
from faster_whisper import WhisperModel, BatchedInferencePipeline
model = WhisperModel("turbo", device="cuda", compute_type="float16")
batched_model = BatchedInferencePipeline(model=model)
segments, info = batched_model.transcribe("audio.mp3", batch_size=16)
for segment in segments:
  print("[%.2fs -> %.2fs] %s" % (segment.start, segment.end, segment.text))
```

### Faster Distil-Whisper
[](https://github.com/SYSTRAN/<#faster-distil-whisper>)
The Distil-Whisper checkpoints are compatible with the Faster-Whisper package. In particular, the latest [distil-large-v3](https://github.com/SYSTRAN/<https:/huggingface.co/distil-whisper/distil-large-v3>) checkpoint is intrinsically designed to work with the Faster-Whisper transcription algorithm. The following code snippet demonstrates how to run inference with distil-large-v3 on a specified audio file:
```
from faster_whisper import WhisperModel
model_size = "distil-large-v3"
model = WhisperModel(model_size, device="cuda", compute_type="float16")
segments, info = model.transcribe("audio.mp3", beam_size=5, language="en", condition_on_previous_text=False)
for segment in segments:
  print("[%.2fs -> %.2fs] %s" % (segment.start, segment.end, segment.text))
```

For more information about the distil-large-v3 model, refer to the original [model card](https://github.com/SYSTRAN/<https:/huggingface.co/distil-whisper/distil-large-v3>).
### Word-level timestamps
[](https://github.com/SYSTRAN/<#word-level-timestamps>)
```
segments, _ = model.transcribe("audio.mp3", word_timestamps=True)
for segment in segments:
  for word in segment.words:
    print("[%.2fs -> %.2fs] %s" % (word.start, word.end, word.word))
```

### VAD filter
[](https://github.com/SYSTRAN/<#vad-filter>)
The library integrates the [Silero VAD](https://github.com/SYSTRAN/<https:/github.com/snakers4/silero-vad>) model to filter out parts of the audio without speech:
```
segments, _ = model.transcribe("audio.mp3", vad_filter=True)
```

The default behavior is conservative and only removes silence longer than 2 seconds. See the available VAD parameters and default values in the [source code](https://github.com/SYSTRAN/<https:/github.com/SYSTRAN/faster-whisper/blob/master/faster_whisper/vad.py>). They can be customized with the dictionary argument `vad_parameters`:
```
segments, _ = model.transcribe(
  "audio.mp3",
  vad_filter=True,
  vad_parameters=dict(min_silence_duration_ms=500),
)
```

Vad filter is enabled by default for batched transcription.
### Logging
[](https://github.com/SYSTRAN/<#logging>)
The library logging level can be configured like this:
```
import logging
logging.basicConfig()
logging.getLogger("faster_whisper").setLevel(logging.DEBUG)
```

### Going further
[](https://github.com/SYSTRAN/<#going-further>)
See more model and transcription options in the `WhisperModel`[](https://github.com/SYSTRAN/<https:/github.com/SYSTRAN/faster-whisper/blob/master/faster_whisper/transcribe.py>) class implementation.
## Community integrations
[](https://github.com/SYSTRAN/<#community-integrations>)
Here is a non exhaustive list of open-source projects using faster-whisper. Feel free to add your project to the list!
  * [faster-whisper-server](https://github.com/SYSTRAN/<https:/github.com/fedirz/faster-whisper-server>) is an OpenAI compatible server using `faster-whisper`. It's easily deployable with Docker, works with OpenAI SDKs/CLI, supports streaming, and live transcription.
  * [WhisperX](https://github.com/SYSTRAN/<https:/github.com/m-bain/whisperX>) is an award-winning Python library that offers speaker diarization and accurate word-level timestamps using wav2vec2 alignment
  * [whisper-ctranslate2](https://github.com/SYSTRAN/<https:/github.com/Softcatala/whisper-ctranslate2>) is a command line client based on faster-whisper and compatible with the original client from openai/whisper.
  * [whisper-diarize](https://github.com/SYSTRAN/<https:/github.com/MahmoudAshraf97/whisper-diarization>) is a speaker diarization tool that is based on faster-whisper and NVIDIA NeMo.
  * [whisper-standalone-win](https://github.com/SYSTRAN/<https:/github.com/Purfview/whisper-standalone-win>) Standalone CLI executables of faster-whisper for Windows, Linux & macOS.
  * [asr-sd-pipeline](https://github.com/SYSTRAN/<https:/github.com/hedrergudene/asr-sd-pipeline>) provides a scalable, modular, end to end multi-speaker speech to text solution implemented using AzureML pipelines.
  * [Open-Lyrics](https://github.com/SYSTRAN/<https:/github.com/zh-plus/Open-Lyrics>) is a Python library that transcribes voice files using faster-whisper, and translates/polishes the resulting text into `.lrc` files in the desired language using OpenAI-GPT.
  * [wscribe](https://github.com/SYSTRAN/<https:/github.com/geekodour/wscribe>) is a flexible transcript generation tool supporting faster-whisper, it can export word level transcript and the exported transcript then can be edited with [wscribe-editor](https://github.com/SYSTRAN/<https:/github.com/geekodour/wscribe-editor>)
  * [aTrain](https://github.com/SYSTRAN/<https:/github.com/BANDAS-Center/aTrain>) is a graphical user interface implementation of faster-whisper developed at the BANDAS-Center at the University of Graz for transcription and diarization in Windows ([Windows Store App](https://github.com/SYSTRAN/<https:/apps.microsoft.com/detail/atrain/9N15Q44SZNS2>)) and Linux.
  * [Whisper-Streaming](https://github.com/SYSTRAN/<https:/github.com/ufal/whisper_streaming>) implements real-time mode for offline Whisper-like speech-to-text models with faster-whisper as the most recommended back-end. It implements a streaming policy with self-adaptive latency based on the actual source complexity, and demonstrates the state of the art.
  * [WhisperLive](https://github.com/SYSTRAN/<https:/github.com/collabora/WhisperLive>) is a nearly-live implementation of OpenAI's Whisper which uses faster-whisper as the backend to transcribe audio in real-time.
  * [Faster-Whisper-Transcriber](https://github.com/SYSTRAN/<https:/github.com/BBC-Esq/ctranslate2-faster-whisper-transcriber>) is a simple but reliable voice transcriber that provides a user-friendly interface.
  * [Open-dubbing](https://github.com/SYSTRAN/<https:/github.com/softcatala/open-dubbing>) is open dubbing is an AI dubbing system which uses machine learning models to automatically translate and synchronize audio dialogue into different languages.


## Model conversion
[](https://github.com/SYSTRAN/<#model-conversion>)
When loading a model from its size such as `WhisperModel("large-v3")`, the corresponding CTranslate2 model is automatically downloaded from the [Hugging Face Hub](https://github.com/SYSTRAN/<https:/huggingface.co/Systran>).
We also provide a script to convert any Whisper models compatible with the Transformers library. They could be the original OpenAI models or user fine-tuned models.
For example the command below converts the [original "large-v3" Whisper model](https://github.com/SYSTRAN/<https:/huggingface.co/openai/whisper-large-v3>) and saves the weights in FP16:
```
pip install transformers[torch]>=4.23
ct2-transformers-converter --model openai/whisper-large-v3 --output_dir whisper-large-v3-ct2
--copy_files tokenizer.json preprocessor_config.json --quantization float16
```

  * The option `--model` accepts a model name on the Hub or a path to a model directory.
  * If the option `--copy_files tokenizer.json` is not used, the tokenizer configuration is automatically downloaded when the model is loaded later.


Models can also be converted from the code. See the [conversion API](https://github.com/SYSTRAN/<https:/opennmt.net/CTranslate2/python/ctranslate2.converters.TransformersConverter.html>).
### Load a converted model
[](https://github.com/SYSTRAN/<#load-a-converted-model>)
  1. Directly load the model from a local directory:


```
model = faster_whisper.WhisperModel("whisper-large-v3-ct2")
```

  1. [Upload your model to the Hugging Face Hub](https://github.com/SYSTRAN/<https:/huggingface.co/docs/transformers/model_sharing#upload-with-the-web-interface>) and load it from its name:


```
model = faster_whisper.WhisperModel("username/whisper-large-v3-ct2")
```

## Comparing performance against other implementations
[](https://github.com/SYSTRAN/<#comparing-performance-against-other-implementations>)
If you are comparing the performance against other Whisper implementations, you should make sure to run the comparison with similar settings. In particular:
  * Verify that the same transcription options are used, especially the same beam size. For example in openai/whisper, `model.transcribe` uses a default beam size of 1 but here we use a default beam size of 5.
  * Transcription speed is closely affected by the number of words in the transcript, so ensure that other implementations have a similar WER (Word Error Rate) to this one.
  * When running on CPU, make sure to set the same number of threads. Many frameworks will read the environment variable `OMP_NUM_THREADS`, which can be set when running your script:


```
OMP_NUM_THREADS=4 python3 my_script.py
```

## Footnotes
  1. transformers OOM for any batch size > 1 [↩](https://github.com/SYSTRAN/<#user-content-fnref-1-1b7a39b9e8c4b08111340108775e2bdb>)


## About
Faster Whisper transcription with CTranslate2 
### Topics
[ deep-learning ](https://github.com/SYSTRAN/</topics/deep-learning> "Topic: deep-learning") [ inference ](https://github.com/SYSTRAN/</topics/inference> "Topic: inference") [ transformer ](https://github.com/SYSTRAN/</topics/transformer> "Topic: transformer") [ speech-recognition ](https://github.com/SYSTRAN/</topics/speech-recognition> "Topic: speech-recognition") [ openai ](https://github.com/SYSTRAN/</topics/openai> "Topic: openai") [ speech-to-text ](https://github.com/SYSTRAN/</topics/speech-to-text> "Topic: speech-to-text") [ quantization ](https://github.com/SYSTRAN/</topics/quantization> "Topic: quantization") [ whisper ](https://github.com/SYSTRAN/</topics/whisper> "Topic: whisper")
### Resources
[ Readme ](https://github.com/SYSTRAN/<#readme-ov-file>)
### License
[ MIT license ](https://github.com/SYSTRAN/<#MIT-1-ov-file>)
[ Activity](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/activity>)
[ Custom properties](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/custom-properties>)
### Stars
[ **14.1k** stars](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/stargazers>)
### Watchers
[ **131** watching](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/watchers>)
### Forks
[ **1.2k** forks](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/forks>)
[ Report repository ](https://github.com/SYSTRAN/</contact/report-content?content_url=https%3A%2F%2Fgithub.com%2FSYSTRAN%2Ffaster-whisper&report=SYSTRAN+%28user%29>)
##  [Releases 19](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/releases>)
[ faster-whisper 1.1.1 Latest  Jan 1, 2025 ](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/releases/tag/v1.1.1>)
[+ 18 releases](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/releases>)
##  [Used by 3.9k](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/network/dependents>)
[
  * ![@saikrn112](https://avatars.githubusercontent.com/u/12894498?s=64&v=4)
  * ![@iagentic](https://avatars.githubusercontent.com/u/185085971?s=64&v=4)
  * ![@AtlasRoseblume](https://avatars.githubusercontent.com/u/161170344?s=64&v=4)
  * ![@ajayOrisys](https://avatars.githubusercontent.com/u/162582428?s=64&v=4)
  * ![@strangetamer43](https://avatars.githubusercontent.com/u/86204643?s=64&v=4)
  * ![@Natix1](https://avatars.githubusercontent.com/u/96585803?s=64&v=4)
  * ![@ayutaz](https://avatars.githubusercontent.com/u/41669061?s=64&v=4)
  * ![@mo7amed7assan1911](https://avatars.githubusercontent.com/u/55090589?s=64&v=4)

+ 3,855  ](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/network/dependents>)
##  [Contributors 44](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/graphs/contributors>)
  * [ ![@guillaumekln](https://avatars.githubusercontent.com/u/4805513?s=64&v=4) ](https://github.com/SYSTRAN/<https:/github.com/guillaumekln>)
  * [ ![@MahmoudAshraf97](https://avatars.githubusercontent.com/u/32404268?s=64&v=4) ](https://github.com/SYSTRAN/<https:/github.com/MahmoudAshraf97>)
  * [ ![@Purfview](https://avatars.githubusercontent.com/u/69023953?s=64&v=4) ](https://github.com/SYSTRAN/<https:/github.com/Purfview>)
  * [ ![@trungkienbkhn](https://avatars.githubusercontent.com/u/48075757?s=64&v=4) ](https://github.com/SYSTRAN/<https:/github.com/trungkienbkhn>)
  * [ ![@jordimas](https://avatars.githubusercontent.com/u/309265?s=64&v=4) ](https://github.com/SYSTRAN/<https:/github.com/jordimas>)
  * [ ![@hoonlight](https://avatars.githubusercontent.com/u/98728125?s=64&v=4) ](https://github.com/SYSTRAN/<https:/github.com/hoonlight>)
  * [ ![@zh-plus](https://avatars.githubusercontent.com/u/29461582?s=64&v=4) ](https://github.com/SYSTRAN/<https:/github.com/zh-plus>)
  * [ ![@FlippFuzz](https://avatars.githubusercontent.com/u/41221030?s=64&v=4) ](https://github.com/SYSTRAN/<https:/github.com/FlippFuzz>)
  * [ ![@ozancaglayan](https://avatars.githubusercontent.com/u/330946?s=64&v=4) ](https://github.com/SYSTRAN/<https:/github.com/ozancaglayan>)
  * [ ![@mayeaux](https://avatars.githubusercontent.com/u/7200471?s=64&v=4) ](https://github.com/SYSTRAN/<https:/github.com/mayeaux>)
  * [ ![@heimoshuiyu](https://avatars.githubusercontent.com/u/22657774?s=64&v=4) ](https://github.com/SYSTRAN/<https:/github.com/heimoshuiyu>)
  * [ ![@Keating950](https://avatars.githubusercontent.com/u/43932454?s=64&v=4) ](https://github.com/SYSTRAN/<https:/github.com/Keating950>)
  * [ ![@fedirz](https://avatars.githubusercontent.com/u/76551385?s=64&v=4) ](https://github.com/SYSTRAN/<https:/github.com/fedirz>)
  * [ ![@peterk](https://avatars.githubusercontent.com/u/19284?s=64&v=4) ](https://github.com/SYSTRAN/<https:/github.com/peterk>)


[+ 30 contributors](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/graphs/contributors>)
## Languages
  * [ Python 99.9% ](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/search?l=python>)
  * [ Dockerfile 0.1% ](https://github.com/SYSTRAN/</SYSTRAN/faster-whisper/search?l=dockerfile>)


## Footer
[ ](https://github.com/SYSTRAN/<https:/github.com> "GitHub") © 2025 GitHub, Inc. 
### Footer navigation
  * [Terms](https://github.com/SYSTRAN/<https:/docs.github.com/site-policy/github-terms/github-terms-of-service>)
  * [Privacy](https://github.com/SYSTRAN/<https:/docs.github.com/site-policy/privacy-policies/github-privacy-statement>)
  * [Security](https://github.com/SYSTRAN/<https:/github.com/security>)
  * [Status](https://github.com/SYSTRAN/<https:/www.githubstatus.com/>)
  * [Docs](https://github.com/SYSTRAN/<https:/docs.github.com/>)
  * [Contact](https://github.com/SYSTRAN/<https:/support.github.com?tags=dotcom-footer>)
  * Manage cookies 
  * Do not share my personal information 


You can’t perform that action at this time. 
